{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d3cf7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9281fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  #Passengers\n",
       "0  1949-01          112\n",
       "1  1949-02          118\n",
       "2  1949-03          132\n",
       "3  1949-04          129\n",
       "4  1949-05          121"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../deep_source_files/AirPassengers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6446c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  #Passengers\n",
       "139  1960-08          606\n",
       "140  1960-09          508\n",
       "141  1960-10          461\n",
       "142  1960-11          390\n",
       "143  1960-12          432"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd244170",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Month        144 non-null    object\n",
      " 1   #Passengers  144 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd19f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과거 5개월의 데이터를 학습해서 다음 년도의 탑승객 수를 예측하는 모델을 만들고,\n",
    "# 1960-07 ~ 1960-11의 5개월 데이터를 기반으로 1960-12월의 탑승객의 수를 예측하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f801fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mon'] = df.Month.apply(lambda x: x.split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81d23f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>#Passengers</th>\n",
       "      <th>mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  #Passengers mon\n",
       "0  1949-01          112  01\n",
       "1  1949-02          118  02\n",
       "2  1949-03          132  03\n",
       "3  1949-04          129  04\n",
       "4  1949-05          121  05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a475865b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mon\n",
       "01    241.750000\n",
       "02    235.000000\n",
       "03    270.166667\n",
       "04    267.083333\n",
       "05    271.833333\n",
       "06    311.666667\n",
       "07    351.333333\n",
       "08    351.083333\n",
       "09    302.416667\n",
       "10    266.583333\n",
       "11    232.833333\n",
       "12    261.833333\n",
       "Name: #Passengers, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('mon')['#Passengers'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b857295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df.iloc[:-1, :]\n",
    "# df_test = df.iloc[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5fc68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48108b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "130dc23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>#Passengers</th>\n",
       "      <th>mon</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08</td>\n",
       "      <td>606</td>\n",
       "      <td>08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09</td>\n",
       "      <td>508</td>\n",
       "      <td>09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10</td>\n",
       "      <td>461</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11</td>\n",
       "      <td>390</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12</td>\n",
       "      <td>432</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  #Passengers mon    0    1    2    3    4    5    6    7    8  \\\n",
       "139  1960-08          606  08  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "140  1960-09          508  09  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "141  1960-10          461  10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "142  1960-11          390  11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "143  1960-12          432  12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       9   10   11   12  \n",
       "139  0.0  0.0  0.0  0.0  \n",
       "140  1.0  0.0  0.0  0.0  \n",
       "141  0.0  1.0  0.0  0.0  \n",
       "142  0.0  0.0  1.0  0.0  \n",
       "143  0.0  0.0  0.0  1.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_con = pd.concat([df, pd.DataFrame(to_categorical(df.mon, num_classes=13))], axis=1)\n",
    "df_con.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_con.iloc[:-1, :]\n",
    "# df_test = df_con.iloc[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232d983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06f73aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, '#Passengers']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(range(1, 13))\n",
    "cols.append('#Passengers')\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "232af483",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8    9   10   11   12  #Passengers\n",
       "0    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          112\n",
       "1    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          118\n",
       "2    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          132\n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          129\n",
       "4    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          121\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...          ...\n",
       "139  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0          606\n",
       "140  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0          508\n",
       "141  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0          461\n",
       "142  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0          390\n",
       "143  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0          432\n",
       "\n",
       "[144 rows x 13 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_con = df_con[cols]\n",
    "df_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a29b0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_con.iloc[:-1, :]\n",
    "df_test = df_con.iloc[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc559395",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8    9   10   11   12  #Passengers\n",
       "0    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          112\n",
       "1    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          118\n",
       "2    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          132\n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          129\n",
       "4    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          121\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...          ...\n",
       "138  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0          622\n",
       "139  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0          606\n",
       "140  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0          508\n",
       "141  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0          461\n",
       "142  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0          390\n",
       "\n",
       "[143 rows x 13 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a7673ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd46aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "window_size = 5\n",
    "\n",
    "for i in range(len(x_train) - window_size-1):\n",
    "    X.append(x_train[i:i+window_size])\n",
    "    Y.append(x_train[i+window_size+1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199d842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8877c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "594b826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c80fb606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 5, 13)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce3f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a36ed75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0bb12070",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 5, 15)             1740      \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 15)                1860      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               2048      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,017\n",
      "Trainable params: 16,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(15, input_shape=(5,13), return_sequences=True))\n",
    "model.add(LSTM(15))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a7a09383",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "57495270",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 67962.4609 - mse: 67962.4609 - val_loss: 197377.2812 - val_mse: 197377.2812\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 64985.8594 - mse: 64985.8516 - val_loss: 188801.8438 - val_mse: 188801.8438\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57500.8359 - mse: 57500.8359 - val_loss: 162873.1094 - val_mse: 162873.1094\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 37716.1094 - mse: 37716.1094 - val_loss: 105050.7500 - val_mse: 105050.7500\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12984.2549 - mse: 12984.2549 - val_loss: 36642.3828 - val_mse: 36642.3828\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 13525.6689 - mse: 13525.6689 - val_loss: 40514.2617 - val_mse: 40514.2617\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9625.2021 - mse: 9625.2021 - val_loss: 52014.3203 - val_mse: 52014.3203\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10822.1406 - mse: 10822.1406 - val_loss: 47398.7461 - val_mse: 47398.7422\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8519.8789 - mse: 8519.8789 - val_loss: 42469.2852 - val_mse: 42469.2852\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 10750.2178 - mse: 10750.2178 - val_loss: 43663.3750 - val_mse: 43663.3750\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10633.8623 - mse: 10633.8623 - val_loss: 46486.7383 - val_mse: 46486.7383\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9719.6270 - mse: 9719.6270 - val_loss: 52382.8047 - val_mse: 52382.8047\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9542.9297 - mse: 9542.9297 - val_loss: 38795.5312 - val_mse: 38795.5312\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7562.2231 - mse: 7562.2231 - val_loss: 40548.7773 - val_mse: 40548.7773\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8253.2822 - mse: 8253.2822 - val_loss: 38020.2539 - val_mse: 38020.2539\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7211.6079 - mse: 7211.6079 - val_loss: 31657.3906 - val_mse: 31657.3906\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7712.4849 - mse: 7712.4849 - val_loss: 36884.4648 - val_mse: 36884.4648\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6484.7471 - mse: 6484.7471 - val_loss: 26623.5527 - val_mse: 26623.5527\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5298.2959 - mse: 5298.2959 - val_loss: 29868.3633 - val_mse: 29868.3633\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5326.2896 - mse: 5326.2896 - val_loss: 22866.7969 - val_mse: 22866.7969\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4539.3862 - mse: 4539.3862 - val_loss: 16155.6201 - val_mse: 16155.6201\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 6378.8145 - mse: 6378.8145 - val_loss: 17724.7656 - val_mse: 17724.7656\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4704.8545 - mse: 4704.8545 - val_loss: 20000.4023 - val_mse: 20000.4023\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5158.8257 - mse: 5158.8257 - val_loss: 24847.8008 - val_mse: 24847.8008\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3761.6841 - mse: 3761.6841 - val_loss: 15063.6543 - val_mse: 15063.6543\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4375.6685 - mse: 4375.6685 - val_loss: 13164.2793 - val_mse: 13164.2793\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4944.1055 - mse: 4944.1050 - val_loss: 13203.1719 - val_mse: 13203.1719\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4977.1328 - mse: 4977.1328 - val_loss: 16682.0332 - val_mse: 16682.0332\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3759.7412 - mse: 3759.7412 - val_loss: 12090.5537 - val_mse: 12090.5537\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4026.8870 - mse: 4026.8870 - val_loss: 12197.7920 - val_mse: 12197.7920\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3821.4106 - mse: 3821.4106 - val_loss: 14791.6787 - val_mse: 14791.6787\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4280.2363 - mse: 4280.2363 - val_loss: 11609.2451 - val_mse: 11609.2451\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3869.8723 - mse: 3869.8723 - val_loss: 11496.2344 - val_mse: 11496.2344\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3066.9846 - mse: 3066.9846 - val_loss: 10083.2705 - val_mse: 10083.2705\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3452.4929 - mse: 3452.4929 - val_loss: 14310.5527 - val_mse: 14310.5527\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5442.1274 - mse: 5442.1274 - val_loss: 32785.4609 - val_mse: 32785.4609\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5911.0269 - mse: 5911.0269 - val_loss: 13037.9521 - val_mse: 13037.9521\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4378.9580 - mse: 4378.9580 - val_loss: 14033.0068 - val_mse: 14033.0068\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3438.6829 - mse: 3438.6829 - val_loss: 17495.9746 - val_mse: 17495.9746\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4961.1216 - mse: 4961.1221 - val_loss: 11827.9775 - val_mse: 11827.9775\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4491.7573 - mse: 4491.7573 - val_loss: 12518.0957 - val_mse: 12518.0957\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2951.8831 - mse: 2951.8831 - val_loss: 11347.8975 - val_mse: 11347.8975\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3742.7073 - mse: 3742.7073 - val_loss: 12444.3926 - val_mse: 12444.3926\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2747.6238 - mse: 2747.6238 - val_loss: 11188.4229 - val_mse: 11188.4229\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3039.4412 - mse: 3039.4412 - val_loss: 12831.6025 - val_mse: 12831.6025\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2657.0071 - mse: 2657.0071 - val_loss: 8255.3564 - val_mse: 8255.3564\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2516.1289 - mse: 2516.1289 - val_loss: 8718.7666 - val_mse: 8718.7666\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2860.7808 - mse: 2860.7808 - val_loss: 11344.8213 - val_mse: 11344.8213\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2699.7847 - mse: 2699.7847 - val_loss: 7833.7422 - val_mse: 7833.7422\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2794.9058 - mse: 2794.9060 - val_loss: 5737.8623 - val_mse: 5737.8623\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4392.8706 - mse: 4392.8706 - val_loss: 6070.4507 - val_mse: 6070.4507\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2467.2297 - mse: 2467.2297 - val_loss: 6902.6484 - val_mse: 6902.6484\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3692.9536 - mse: 3692.9536 - val_loss: 7416.3369 - val_mse: 7416.3369\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2936.8630 - mse: 2936.8630 - val_loss: 9863.1270 - val_mse: 9863.1270\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3063.2412 - mse: 3063.2412 - val_loss: 5390.0635 - val_mse: 5390.0635\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2746.4626 - mse: 2746.4626 - val_loss: 6612.3335 - val_mse: 6612.3335\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 3016.0327 - mse: 3016.0327 - val_loss: 6817.6763 - val_mse: 6817.6763\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3534.7520 - mse: 3534.7520 - val_loss: 5634.3706 - val_mse: 5634.3706\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2479.2827 - mse: 2479.2827 - val_loss: 5281.9253 - val_mse: 5281.9253\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3012.0825 - mse: 3012.0825 - val_loss: 5027.3931 - val_mse: 5027.3931\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2907.9734 - mse: 2907.9731 - val_loss: 5693.0630 - val_mse: 5693.0630\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2420.4998 - mse: 2420.4998 - val_loss: 4674.4380 - val_mse: 4674.4380\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2780.1477 - mse: 2780.1477 - val_loss: 5589.4990 - val_mse: 5589.4990\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2938.6838 - mse: 2938.6838 - val_loss: 4158.5786 - val_mse: 4158.5786\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2640.8892 - mse: 2640.8892 - val_loss: 4861.6172 - val_mse: 4861.6172\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2590.2861 - mse: 2590.2864 - val_loss: 5707.0708 - val_mse: 5707.0708\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3103.5295 - mse: 3103.5298 - val_loss: 4232.8208 - val_mse: 4232.8208\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3382.3872 - mse: 3382.3872 - val_loss: 6527.7759 - val_mse: 6527.7759\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3175.8323 - mse: 3175.8323 - val_loss: 7783.0967 - val_mse: 7783.0967\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2144.7769 - mse: 2144.7769 - val_loss: 6662.2661 - val_mse: 6662.2661\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2055.2737 - mse: 2055.2737 - val_loss: 4683.4448 - val_mse: 4683.4448\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2440.3958 - mse: 2440.3958 - val_loss: 4100.2515 - val_mse: 4100.2515\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2051.7402 - mse: 2051.7402 - val_loss: 8122.6406 - val_mse: 8122.6406\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2305.3970 - mse: 2305.3970 - val_loss: 10725.9551 - val_mse: 10725.9551\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1828.5704 - mse: 1828.5704 - val_loss: 4757.8354 - val_mse: 4757.8354\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2512.1287 - mse: 2512.1287 - val_loss: 3813.9019 - val_mse: 3813.9019\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1788.3889 - mse: 1788.3889 - val_loss: 3500.1643 - val_mse: 3500.1643\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2130.5217 - mse: 2130.5220 - val_loss: 4150.6646 - val_mse: 4150.6646\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3036.2373 - mse: 3036.2373 - val_loss: 3793.6541 - val_mse: 3793.6541\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1532.8020 - mse: 1532.8020 - val_loss: 3953.1660 - val_mse: 3953.1660\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2550.1699 - mse: 2550.1699 - val_loss: 4048.2791 - val_mse: 4048.2791\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1778.5970 - mse: 1778.5970 - val_loss: 5489.3057 - val_mse: 5489.3057\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2270.2935 - mse: 2270.2935 - val_loss: 6172.7925 - val_mse: 6172.7925\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2269.1765 - mse: 2269.1765 - val_loss: 8893.9463 - val_mse: 8893.9463\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1831.9211 - mse: 1831.9211 - val_loss: 5891.3213 - val_mse: 5891.3213\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1897.8783 - mse: 1897.8783 - val_loss: 8714.1270 - val_mse: 8714.1270\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1783.6371 - mse: 1783.6371 - val_loss: 3505.5105 - val_mse: 3505.5105\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2575.2515 - mse: 2575.2515 - val_loss: 3459.8640 - val_mse: 3459.8640\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2738.4644 - mse: 2738.4644 - val_loss: 3058.7397 - val_mse: 3058.7400\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1992.5046 - mse: 1992.5046 - val_loss: 3145.9851 - val_mse: 3145.9851\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2035.2306 - mse: 2035.2306 - val_loss: 3303.2952 - val_mse: 3303.2952\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1617.7222 - mse: 1617.7222 - val_loss: 6791.2241 - val_mse: 6791.2241\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1535.4337 - mse: 1535.4337 - val_loss: 4657.1118 - val_mse: 4657.1113\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2035.5964 - mse: 2035.5964 - val_loss: 5018.0000 - val_mse: 5018.0000\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1867.2881 - mse: 1867.2881 - val_loss: 19499.3848 - val_mse: 19499.3848\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3474.3457 - mse: 3474.3457 - val_loss: 7793.2310 - val_mse: 7793.2310\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2478.2981 - mse: 2478.2981 - val_loss: 5093.0649 - val_mse: 5093.0649\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1302.9301 - mse: 1302.9301 - val_loss: 3801.3750 - val_mse: 3801.3750\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2406.4409 - mse: 2406.4409 - val_loss: 2959.6323 - val_mse: 2959.6323\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1620.6613 - mse: 1620.6613 - val_loss: 3031.2341 - val_mse: 3031.2341\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1704.3761 - mse: 1704.3761 - val_loss: 3237.5344 - val_mse: 3237.5344\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1633.4640 - mse: 1633.4640 - val_loss: 7477.3750 - val_mse: 7477.3750\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1451.9564 - mse: 1451.9564 - val_loss: 2152.3469 - val_mse: 2152.3469\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2108.8369 - mse: 2108.8369 - val_loss: 2627.0720 - val_mse: 2627.0720\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1818.5189 - mse: 1818.5188 - val_loss: 2978.4766 - val_mse: 2978.4766\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1172.2587 - mse: 1172.2588 - val_loss: 3444.6077 - val_mse: 3444.6077\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1807.3685 - mse: 1807.3685 - val_loss: 5955.5708 - val_mse: 5955.5708\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1500.6128 - mse: 1500.6128 - val_loss: 1669.8207 - val_mse: 1669.8207\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2383.2251 - mse: 2383.2251 - val_loss: 2073.4934 - val_mse: 2073.4934\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 983.9016 - mse: 983.9016 - val_loss: 3959.8337 - val_mse: 3959.8337\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2005.6757 - mse: 2005.6754 - val_loss: 8472.6279 - val_mse: 8472.6279\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2061.6252 - mse: 2061.6252 - val_loss: 4524.7612 - val_mse: 4524.7612\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1198.1885 - mse: 1198.1885 - val_loss: 2255.1702 - val_mse: 2255.1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1271.6160 - mse: 1271.6158 - val_loss: 4751.1255 - val_mse: 4751.1255\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1624.7305 - mse: 1624.7305 - val_loss: 1608.3340 - val_mse: 1608.3340\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1227.7117 - mse: 1227.7117 - val_loss: 2491.8931 - val_mse: 2491.8931\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1569.5154 - mse: 1569.5154 - val_loss: 2433.5803 - val_mse: 2433.5803\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1656.5944 - mse: 1656.5944 - val_loss: 6643.9248 - val_mse: 6643.9248\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2007.9485 - mse: 2007.9485 - val_loss: 11956.4268 - val_mse: 11956.4268\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2195.8721 - mse: 2195.8721 - val_loss: 4671.4048 - val_mse: 4671.4048\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1368.7764 - mse: 1368.7764 - val_loss: 2017.7716 - val_mse: 2017.7716\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1097.5946 - mse: 1097.5946 - val_loss: 6370.3115 - val_mse: 6370.3115\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1260.9698 - mse: 1260.9698 - val_loss: 1787.5931 - val_mse: 1787.5931\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1147.2413 - mse: 1147.2413 - val_loss: 1575.3340 - val_mse: 1575.3340\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1587.2240 - mse: 1587.2240 - val_loss: 3564.5659 - val_mse: 3564.5659\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2171.6484 - mse: 2171.6484 - val_loss: 1614.2489 - val_mse: 1614.2489\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1179.1284 - mse: 1179.1284 - val_loss: 3593.0251 - val_mse: 3593.0251\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1394.7643 - mse: 1394.7643 - val_loss: 4123.3906 - val_mse: 4123.3906\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1074.6879 - mse: 1074.6879 - val_loss: 4310.1431 - val_mse: 4310.1431\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1685.2294 - mse: 1685.2291 - val_loss: 1677.8507 - val_mse: 1677.8507\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2029.0500 - mse: 2029.0499 - val_loss: 2722.0593 - val_mse: 2722.0593\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1747.9373 - mse: 1747.9373 - val_loss: 6532.3711 - val_mse: 6532.3706\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1781.8419 - mse: 1781.8419 - val_loss: 2802.0178 - val_mse: 2802.0178\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1296.3751 - mse: 1296.3750 - val_loss: 2100.9414 - val_mse: 2100.9414\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1630.8824 - mse: 1630.8826 - val_loss: 2362.1687 - val_mse: 2362.1687\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1165.7327 - mse: 1165.7327 - val_loss: 3000.8794 - val_mse: 3000.8794\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1363.2454 - mse: 1363.2454 - val_loss: 2196.3010 - val_mse: 2196.3010\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1411.8572 - mse: 1411.8572 - val_loss: 10225.4131 - val_mse: 10225.4131\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1427.3444 - mse: 1427.3444 - val_loss: 4594.7993 - val_mse: 4594.7993\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1730.2969 - mse: 1730.2969 - val_loss: 8557.4512 - val_mse: 8557.4512\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1936.8241 - mse: 1936.8241 - val_loss: 6880.2905 - val_mse: 6880.2905\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1238.0480 - mse: 1238.0480 - val_loss: 4708.9893 - val_mse: 4708.9893\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1077.0083 - mse: 1077.0083 - val_loss: 2389.9236 - val_mse: 2389.9236\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1185.9937 - mse: 1185.9937 - val_loss: 6656.7803 - val_mse: 6656.7803\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1082.5942 - mse: 1082.5942 - val_loss: 2239.0408 - val_mse: 2239.0408\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1211.0792 - mse: 1211.0792 - val_loss: 2593.2585 - val_mse: 2593.2583\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1410.5334 - mse: 1410.5334 - val_loss: 2433.4570 - val_mse: 2433.4570\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1207.4235 - mse: 1207.4235 - val_loss: 3089.3230 - val_mse: 3089.3230\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1503.2920 - mse: 1503.2920 - val_loss: 6284.4443 - val_mse: 6284.4443\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1215.6001 - mse: 1215.6001 - val_loss: 7494.7759 - val_mse: 7494.7759\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1713.3237 - mse: 1713.3237 - val_loss: 1541.8258 - val_mse: 1541.8258\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1500.7070 - mse: 1500.7070 - val_loss: 9809.7344 - val_mse: 9809.7344\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1714.7631 - mse: 1714.7631 - val_loss: 8169.5659 - val_mse: 8169.5659\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1335.2595 - mse: 1335.2595 - val_loss: 1322.8611 - val_mse: 1322.8611\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1599.5956 - mse: 1599.5956 - val_loss: 3053.6021 - val_mse: 3053.6021\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1506.5542 - mse: 1506.5542 - val_loss: 6319.2969 - val_mse: 6319.2969\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1265.6110 - mse: 1265.6110 - val_loss: 7114.1914 - val_mse: 7114.1914\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1332.2135 - mse: 1332.2135 - val_loss: 1740.2767 - val_mse: 1740.2767\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1552.8604 - mse: 1552.8604 - val_loss: 1834.0529 - val_mse: 1834.0529\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1134.2067 - mse: 1134.2067 - val_loss: 8514.3721 - val_mse: 8514.3721\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1371.2312 - mse: 1371.2312 - val_loss: 3854.0977 - val_mse: 3854.0977\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1410.8756 - mse: 1410.8756 - val_loss: 1937.5695 - val_mse: 1937.5695\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1376.1681 - mse: 1376.1681 - val_loss: 4379.9761 - val_mse: 4379.9761\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1507.1644 - mse: 1507.1644 - val_loss: 2363.9934 - val_mse: 2363.9934\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1370.5619 - mse: 1370.5619 - val_loss: 1409.7483 - val_mse: 1409.7483\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1160.8398 - mse: 1160.8398 - val_loss: 1771.4915 - val_mse: 1771.4915\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1037.9839 - mse: 1037.9839 - val_loss: 1396.7631 - val_mse: 1396.7631\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 977.3062 - mse: 977.3062 - val_loss: 1716.0795 - val_mse: 1716.0795\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1134.7428 - mse: 1134.7428 - val_loss: 1286.6183 - val_mse: 1286.6183\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 902.2374 - mse: 902.2374 - val_loss: 4818.6597 - val_mse: 4818.6597\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1007.5750 - mse: 1007.5750 - val_loss: 1381.6902 - val_mse: 1381.6902\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1015.7850 - mse: 1015.7850 - val_loss: 1074.6028 - val_mse: 1074.6028\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 983.1224 - mse: 983.1224 - val_loss: 2701.8589 - val_mse: 2701.8589\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1110.9163 - mse: 1110.9163 - val_loss: 3335.8113 - val_mse: 3335.8113\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1148.6011 - mse: 1148.6011 - val_loss: 1519.2279 - val_mse: 1519.2279\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1460.0969 - mse: 1460.0969 - val_loss: 1645.7307 - val_mse: 1645.7307\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1274.3397 - mse: 1274.3397 - val_loss: 6780.2310 - val_mse: 6780.2310\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 887.2554 - mse: 887.2554 - val_loss: 2593.2834 - val_mse: 2593.2834\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1415.3702 - mse: 1415.3702 - val_loss: 3486.2336 - val_mse: 3486.2336\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 973.2299 - mse: 973.2299 - val_loss: 2619.4016 - val_mse: 2619.4016\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1332.0581 - mse: 1332.0581 - val_loss: 9538.3662 - val_mse: 9538.3662\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1756.8473 - mse: 1756.8475 - val_loss: 9999.1396 - val_mse: 9999.1396\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2143.7175 - mse: 2143.7175 - val_loss: 3881.2771 - val_mse: 3881.2771\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1164.5542 - mse: 1164.5542 - val_loss: 3073.1021 - val_mse: 3073.1021\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1637.9237 - mse: 1637.9237 - val_loss: 1441.4948 - val_mse: 1441.4948\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1662.9612 - mse: 1662.9612 - val_loss: 3456.9778 - val_mse: 3456.9778\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1568.8275 - mse: 1568.8275 - val_loss: 12742.0771 - val_mse: 12742.0771\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1492.8759 - mse: 1492.8759 - val_loss: 4157.7305 - val_mse: 4157.7305\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1497.4646 - mse: 1497.4646 - val_loss: 1555.4286 - val_mse: 1555.4286\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1802.7153 - mse: 1802.7153 - val_loss: 2659.0195 - val_mse: 2659.0195\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1122.2211 - mse: 1122.2211 - val_loss: 2837.9514 - val_mse: 2837.9514\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1115.5679 - mse: 1115.5679 - val_loss: 5058.4800 - val_mse: 5058.4800\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1221.4138 - mse: 1221.4138 - val_loss: 1161.0635 - val_mse: 1161.0635\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1247.2697 - mse: 1247.2697 - val_loss: 1621.9818 - val_mse: 1621.9821\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 731.9532 - mse: 731.9532 - val_loss: 3716.2395 - val_mse: 3716.2395\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1263.3643 - mse: 1263.3643 - val_loss: 1641.1266 - val_mse: 1641.1266\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1089.3492 - mse: 1089.3492 - val_loss: 4909.0273 - val_mse: 4909.0273\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1160.0953 - mse: 1160.0953 - val_loss: 4433.2036 - val_mse: 4433.2036\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1354.9878 - mse: 1354.9878 - val_loss: 1202.4364 - val_mse: 1202.4364\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1488.6996 - mse: 1488.6996 - val_loss: 2745.3323 - val_mse: 2745.3323\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1366.1416 - mse: 1366.1416 - val_loss: 2801.8831 - val_mse: 2801.8831\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1381.0006 - mse: 1381.0006 - val_loss: 7481.5493 - val_mse: 7481.5493\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1204.9688 - mse: 1204.9688 - val_loss: 2723.4448 - val_mse: 2723.4448\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1389.5065 - mse: 1389.5065 - val_loss: 5222.5869 - val_mse: 5222.5869\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1239.1766 - mse: 1239.1766 - val_loss: 1725.6085 - val_mse: 1725.6085\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1521.6816 - mse: 1521.6816 - val_loss: 1715.0508 - val_mse: 1715.0508\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1248.9410 - mse: 1248.9410 - val_loss: 2141.0586 - val_mse: 2141.0586\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 939.6908 - mse: 939.6908 - val_loss: 2874.8667 - val_mse: 2874.8667\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1320.0499 - mse: 1320.0499 - val_loss: 3717.7156 - val_mse: 3717.7156\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 829.2672 - mse: 829.2672 - val_loss: 2405.0396 - val_mse: 2405.0396\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1763.5724 - mse: 1763.5724 - val_loss: 1931.1393 - val_mse: 1931.1393\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1005.4418 - mse: 1005.4418 - val_loss: 3830.3376 - val_mse: 3830.3376\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1194.6387 - mse: 1194.6387 - val_loss: 1924.2854 - val_mse: 1924.2854\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1411.7952 - mse: 1411.7952 - val_loss: 3058.8669 - val_mse: 3058.8669\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1040.6677 - mse: 1040.6677 - val_loss: 2790.7209 - val_mse: 2790.7209\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 837.4363 - mse: 837.4365 - val_loss: 2578.8706 - val_mse: 2578.8706\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1232.0803 - mse: 1232.0803 - val_loss: 1295.3848 - val_mse: 1295.3848\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1243.6555 - mse: 1243.6555 - val_loss: 3497.2908 - val_mse: 3497.2908\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1080.4294 - mse: 1080.4294 - val_loss: 2426.6506 - val_mse: 2426.6506\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1633.9175 - mse: 1633.9175 - val_loss: 2095.2603 - val_mse: 2095.2603\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 966.1570 - mse: 966.1570 - val_loss: 776.1673 - val_mse: 776.1673\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 807.7490 - mse: 807.7490 - val_loss: 985.2775 - val_mse: 985.2775\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1440.3593 - mse: 1440.3593 - val_loss: 6937.2944 - val_mse: 6937.2944\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1194.7844 - mse: 1194.7844 - val_loss: 2354.2678 - val_mse: 2354.2678\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1149.7180 - mse: 1149.7180 - val_loss: 1286.9384 - val_mse: 1286.9384\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1479.7090 - mse: 1479.7090 - val_loss: 1217.4397 - val_mse: 1217.4397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1448.7667 - mse: 1448.7667 - val_loss: 3241.3560 - val_mse: 3241.3560\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1152.2115 - mse: 1152.2115 - val_loss: 9972.3564 - val_mse: 9972.3564\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1755.6030 - mse: 1755.6030 - val_loss: 3713.7200 - val_mse: 3713.7200\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 969.7277 - mse: 969.7277 - val_loss: 1129.1963 - val_mse: 1129.1963\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1059.3965 - mse: 1059.3965 - val_loss: 3681.8035 - val_mse: 3681.8035\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 986.9008 - mse: 986.9008 - val_loss: 3503.9058 - val_mse: 3503.9058\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1154.4592 - mse: 1154.4592 - val_loss: 1942.9718 - val_mse: 1942.9718\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1111.3619 - mse: 1111.3619 - val_loss: 1346.9735 - val_mse: 1346.9735\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1250.2126 - mse: 1250.2126 - val_loss: 1874.5924 - val_mse: 1874.5924\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1055.6993 - mse: 1055.6993 - val_loss: 4374.6289 - val_mse: 4374.6289\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 876.9993 - mse: 876.9993 - val_loss: 4527.1050 - val_mse: 4527.1050\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1082.7836 - mse: 1082.7834 - val_loss: 1782.0848 - val_mse: 1782.0848\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1536.1562 - mse: 1536.1562 - val_loss: 2465.8984 - val_mse: 2465.8984\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1027.9204 - mse: 1027.9205 - val_loss: 948.0954 - val_mse: 948.0954\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1291.7612 - mse: 1291.7612 - val_loss: 1234.4188 - val_mse: 1234.4188\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1257.8708 - mse: 1257.8707 - val_loss: 3672.7617 - val_mse: 3672.7617\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1190.8568 - mse: 1190.8568 - val_loss: 5960.1616 - val_mse: 5960.1616\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1010.3959 - mse: 1010.3958 - val_loss: 1650.2158 - val_mse: 1650.2158\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1136.8043 - mse: 1136.8043 - val_loss: 1575.2673 - val_mse: 1575.2673\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1043.3430 - mse: 1043.3430 - val_loss: 1630.5447 - val_mse: 1630.5447\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1210.2119 - mse: 1210.2119 - val_loss: 972.4093 - val_mse: 972.4093\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1350.7832 - mse: 1350.7832 - val_loss: 899.1579 - val_mse: 899.1579\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1234.1498 - mse: 1234.1498 - val_loss: 1065.5852 - val_mse: 1065.5852\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1137.1729 - mse: 1137.1729 - val_loss: 4490.5991 - val_mse: 4490.5991\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1403.8947 - mse: 1403.8947 - val_loss: 2217.8472 - val_mse: 2217.8472\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1022.9153 - mse: 1022.9153 - val_loss: 1759.3320 - val_mse: 1759.3320\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1643.5930 - mse: 1643.5930 - val_loss: 4440.2417 - val_mse: 4440.2417\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1677.9553 - mse: 1677.9553 - val_loss: 1374.0850 - val_mse: 1374.0850\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1520.7841 - mse: 1520.7841 - val_loss: 1828.9729 - val_mse: 1828.9729\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1369.7482 - mse: 1369.7482 - val_loss: 1333.9160 - val_mse: 1333.9160\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 658.9891 - mse: 658.9891 - val_loss: 937.2440 - val_mse: 937.2440\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1256.6885 - mse: 1256.6885 - val_loss: 1792.6398 - val_mse: 1792.6398\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1003.9864 - mse: 1003.9864 - val_loss: 3695.0579 - val_mse: 3695.0579\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 877.3243 - mse: 877.3243 - val_loss: 1112.1769 - val_mse: 1112.1769\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1159.4828 - mse: 1159.4828 - val_loss: 1241.5906 - val_mse: 1241.5906\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1131.3232 - mse: 1131.3232 - val_loss: 1404.3602 - val_mse: 1404.3604\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 850.0991 - mse: 850.0991 - val_loss: 1320.1442 - val_mse: 1320.1442\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1306.4976 - mse: 1306.4976 - val_loss: 6492.1729 - val_mse: 6492.1729\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1422.8130 - mse: 1422.8130 - val_loss: 1621.5999 - val_mse: 1621.5999\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1100.6458 - mse: 1100.6458 - val_loss: 960.9149 - val_mse: 960.9149\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1006.9385 - mse: 1006.9385 - val_loss: 2684.1938 - val_mse: 2684.1938\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1141.3004 - mse: 1141.3004 - val_loss: 4572.9512 - val_mse: 4572.9512\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1283.5759 - mse: 1283.5759 - val_loss: 3801.4900 - val_mse: 3801.4900\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 935.7263 - mse: 935.7263 - val_loss: 2779.4043 - val_mse: 2779.4043\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1475.3469 - mse: 1475.3469 - val_loss: 4950.9175 - val_mse: 4950.9175\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1317.6898 - mse: 1317.6898 - val_loss: 3718.5837 - val_mse: 3718.5837\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1611.2407 - mse: 1611.2407 - val_loss: 6077.1250 - val_mse: 6077.1250\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1210.5365 - mse: 1210.5365 - val_loss: 2079.4211 - val_mse: 2079.4211\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1216.1265 - mse: 1216.1265 - val_loss: 2921.1072 - val_mse: 2921.1072\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1296.2405 - mse: 1296.2405 - val_loss: 2198.1191 - val_mse: 2198.1191\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 816.7607 - mse: 816.7607 - val_loss: 1019.9274 - val_mse: 1019.9274\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1421.1252 - mse: 1421.1252 - val_loss: 1245.3856 - val_mse: 1245.3856\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1211.9954 - mse: 1211.9954 - val_loss: 1724.9968 - val_mse: 1724.9968\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1204.8981 - mse: 1204.8981 - val_loss: 992.8154 - val_mse: 992.8154\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1342.9159 - mse: 1342.9159 - val_loss: 1606.2177 - val_mse: 1606.2177\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1194.7709 - mse: 1194.7709 - val_loss: 1525.7545 - val_mse: 1525.7545\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1652.6095 - mse: 1652.6095 - val_loss: 895.0444 - val_mse: 895.0444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1276.6406 - mse: 1276.6406 - val_loss: 6022.6753 - val_mse: 6022.6753\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1586.4049 - mse: 1586.4049 - val_loss: 3888.1228 - val_mse: 3888.1228\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1063.3793 - mse: 1063.3793 - val_loss: 1354.4598 - val_mse: 1354.4598\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1001.8458 - mse: 1001.8458 - val_loss: 1325.8955 - val_mse: 1325.8955\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1396.9021 - mse: 1396.9021 - val_loss: 3797.5784 - val_mse: 3797.5784\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1218.8346 - mse: 1218.8347 - val_loss: 4896.3228 - val_mse: 4896.3228\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 761.6670 - mse: 761.6670 - val_loss: 1362.7233 - val_mse: 1362.7233\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 935.3005 - mse: 935.3005 - val_loss: 3632.9526 - val_mse: 3632.9526\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 860.3461 - mse: 860.3459 - val_loss: 3294.7478 - val_mse: 3294.7478\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1249.7656 - mse: 1249.7656 - val_loss: 3797.0178 - val_mse: 3797.0178\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1308.4547 - mse: 1308.4547 - val_loss: 1764.0742 - val_mse: 1764.0742\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1052.7480 - mse: 1052.7480 - val_loss: 2210.5439 - val_mse: 2210.5439\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1301.7190 - mse: 1301.7190 - val_loss: 1048.4110 - val_mse: 1048.4110\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1180.5201 - mse: 1180.5201 - val_loss: 2970.0229 - val_mse: 2970.0229\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1072.7834 - mse: 1072.7834 - val_loss: 1793.7858 - val_mse: 1793.7858\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1520.5508 - mse: 1520.5508 - val_loss: 1252.2595 - val_mse: 1252.2595\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1196.7657 - mse: 1196.7657 - val_loss: 5780.7241 - val_mse: 5780.7241\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1019.1057 - mse: 1019.1057 - val_loss: 4517.8662 - val_mse: 4517.8662\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1198.5458 - mse: 1198.5457 - val_loss: 1883.9401 - val_mse: 1883.9401\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 821.2907 - mse: 821.2907 - val_loss: 2454.2046 - val_mse: 2454.2046\n",
      "Epoch 304/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 991.7495 - mse: 991.7495 - val_loss: 2192.8772 - val_mse: 2192.8772\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1087.7754 - mse: 1087.7754 - val_loss: 3153.8394 - val_mse: 3153.8394\n",
      "Epoch 306/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 950.4013 - mse: 950.4012 - val_loss: 2286.7642 - val_mse: 2286.7642\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1372.1873 - mse: 1372.1874 - val_loss: 1518.5291 - val_mse: 1518.5291\n",
      "Epoch 308/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1093.7238 - mse: 1093.7238 - val_loss: 2352.1157 - val_mse: 2352.1157\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 929.0423 - mse: 929.0424 - val_loss: 5880.8052 - val_mse: 5880.8052\n",
      "Epoch 310/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1557.0280 - mse: 1557.0280 - val_loss: 2956.6516 - val_mse: 2956.6511\n",
      "Epoch 311/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 854.3693 - mse: 854.3692 - val_loss: 1319.6376 - val_mse: 1319.6376\n",
      "Epoch 312/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1262.9633 - mse: 1262.9633 - val_loss: 3182.3533 - val_mse: 3182.3533\n",
      "Epoch 313/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 854.0875 - mse: 854.0875 - val_loss: 5810.9429 - val_mse: 5810.9429\n",
      "Epoch 314/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1075.5216 - mse: 1075.5216 - val_loss: 1369.2411 - val_mse: 1369.2411\n",
      "Epoch 315/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1381.5253 - mse: 1381.5253 - val_loss: 1271.9369 - val_mse: 1271.9369\n",
      "Epoch 316/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1316.5044 - mse: 1316.5044 - val_loss: 6723.6782 - val_mse: 6723.6782\n",
      "Epoch 317/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1117.3364 - mse: 1117.3364 - val_loss: 3060.8052 - val_mse: 3060.8052\n",
      "Epoch 318/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1268.4266 - mse: 1268.4266 - val_loss: 2226.1030 - val_mse: 2226.1030\n",
      "Epoch 319/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1298.5801 - mse: 1298.5801 - val_loss: 2252.9688 - val_mse: 2252.9688\n",
      "Epoch 320/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 909.4109 - mse: 909.4109 - val_loss: 1250.2151 - val_mse: 1250.2151\n",
      "Epoch 321/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 993.4795 - mse: 993.4794 - val_loss: 2108.6453 - val_mse: 2108.6453\n",
      "Epoch 322/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 941.8772 - mse: 941.8772 - val_loss: 3489.8481 - val_mse: 3489.8481\n",
      "Epoch 323/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1220.4825 - mse: 1220.4825 - val_loss: 1415.0031 - val_mse: 1415.0031\n",
      "Epoch 324/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1488.4285 - mse: 1488.4285 - val_loss: 1032.9304 - val_mse: 1032.9304\n",
      "Epoch 325/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 929.5415 - mse: 929.5415 - val_loss: 3457.0979 - val_mse: 3457.0979\n",
      "Epoch 326/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1516.7313 - mse: 1516.7313 - val_loss: 6148.1831 - val_mse: 6148.1831\n",
      "Epoch 327/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 960.3188 - mse: 960.3188 - val_loss: 2054.8743 - val_mse: 2054.8743\n",
      "Epoch 328/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 844.3093 - mse: 844.3093 - val_loss: 6100.8799 - val_mse: 6100.8799\n",
      "Epoch 329/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1064.2753 - mse: 1064.2753 - val_loss: 1260.4242 - val_mse: 1260.4242\n",
      "Epoch 330/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1012.2397 - mse: 1012.2397 - val_loss: 1113.5988 - val_mse: 1113.5988\n",
      "Epoch 331/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 923.1527 - mse: 923.1527 - val_loss: 1075.6862 - val_mse: 1075.6862\n",
      "Epoch 332/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1020.5517 - mse: 1020.5517 - val_loss: 1497.7819 - val_mse: 1497.7819\n",
      "Epoch 333/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1377.0023 - mse: 1377.0023 - val_loss: 4123.2036 - val_mse: 4123.2036\n",
      "Epoch 334/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1006.7635 - mse: 1006.7635 - val_loss: 4099.5889 - val_mse: 4099.5889\n",
      "Epoch 335/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1001.6987 - mse: 1001.6987 - val_loss: 2293.3574 - val_mse: 2293.3574\n",
      "Epoch 336/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1069.1943 - mse: 1069.1943 - val_loss: 1168.4320 - val_mse: 1168.4320\n",
      "Epoch 337/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 928.8087 - mse: 928.8087 - val_loss: 2652.7234 - val_mse: 2652.7234\n",
      "Epoch 338/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 932.7090 - mse: 932.7090 - val_loss: 3767.4773 - val_mse: 3767.4773\n",
      "Epoch 339/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1001.7076 - mse: 1001.7076 - val_loss: 5833.6636 - val_mse: 5833.6641\n",
      "Epoch 340/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1392.4573 - mse: 1392.4573 - val_loss: 1751.6628 - val_mse: 1751.6628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1297.8574 - mse: 1297.8574 - val_loss: 1203.8304 - val_mse: 1203.8304\n",
      "Epoch 342/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1145.2479 - mse: 1145.2479 - val_loss: 4046.2505 - val_mse: 4046.2505\n",
      "Epoch 343/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1055.1218 - mse: 1055.1218 - val_loss: 3889.9536 - val_mse: 3889.9536\n",
      "Epoch 344/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1036.4958 - mse: 1036.4958 - val_loss: 4258.2910 - val_mse: 4258.2910\n",
      "Epoch 345/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1139.9476 - mse: 1139.9476 - val_loss: 2128.3833 - val_mse: 2128.3833\n",
      "Epoch 346/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1046.9520 - mse: 1046.9520 - val_loss: 1213.8752 - val_mse: 1213.8752\n",
      "Epoch 347/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1240.4293 - mse: 1240.4293 - val_loss: 7774.4097 - val_mse: 7774.4097\n",
      "Epoch 348/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1177.9440 - mse: 1177.9438 - val_loss: 1418.7040 - val_mse: 1418.7040\n",
      "Epoch 349/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 945.2423 - mse: 945.2423 - val_loss: 936.8055 - val_mse: 936.8055\n",
      "Epoch 350/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1013.4746 - mse: 1013.4746 - val_loss: 8889.3682 - val_mse: 8889.3682\n",
      "Epoch 351/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1196.8751 - mse: 1196.8751 - val_loss: 3620.8054 - val_mse: 3620.8054\n",
      "Epoch 352/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1242.2661 - mse: 1242.2661 - val_loss: 1679.6328 - val_mse: 1679.6328\n",
      "Epoch 353/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1209.6437 - mse: 1209.6437 - val_loss: 3046.4224 - val_mse: 3046.4224\n",
      "Epoch 354/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1039.2535 - mse: 1039.2535 - val_loss: 12128.4043 - val_mse: 12128.4043\n",
      "Epoch 355/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1229.1426 - mse: 1229.1426 - val_loss: 2738.9099 - val_mse: 2738.9099\n",
      "Epoch 356/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1003.2043 - mse: 1003.2043 - val_loss: 1044.9518 - val_mse: 1044.9518\n",
      "Epoch 357/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1232.8044 - mse: 1232.8044 - val_loss: 3480.3562 - val_mse: 3480.3562\n",
      "Epoch 358/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1236.0721 - mse: 1236.0721 - val_loss: 2851.7910 - val_mse: 2851.7910\n",
      "Epoch 359/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 917.2637 - mse: 917.2637 - val_loss: 2097.7185 - val_mse: 2097.7185\n",
      "Epoch 360/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 786.4816 - mse: 786.4816 - val_loss: 3254.3147 - val_mse: 3254.3147\n",
      "Epoch 361/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1112.1409 - mse: 1112.1409 - val_loss: 2302.3384 - val_mse: 2302.3384\n",
      "Epoch 362/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1175.7003 - mse: 1175.7003 - val_loss: 3422.7952 - val_mse: 3422.7952\n",
      "Epoch 363/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1267.5251 - mse: 1267.5251 - val_loss: 4143.1909 - val_mse: 4143.1909\n",
      "Epoch 364/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1098.2722 - mse: 1098.2722 - val_loss: 2678.5625 - val_mse: 2678.5625\n",
      "Epoch 365/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 982.9950 - mse: 982.9950 - val_loss: 4155.3843 - val_mse: 4155.3838\n",
      "Epoch 366/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1217.6921 - mse: 1217.6921 - val_loss: 1709.6219 - val_mse: 1709.6219\n",
      "Epoch 367/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 857.9374 - mse: 857.9374 - val_loss: 2033.7672 - val_mse: 2033.7672\n",
      "Epoch 368/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 841.4177 - mse: 841.4177 - val_loss: 1760.4266 - val_mse: 1760.4266\n",
      "Epoch 369/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1022.6460 - mse: 1022.6460 - val_loss: 3177.9700 - val_mse: 3177.9700\n",
      "Epoch 370/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1173.6465 - mse: 1173.6465 - val_loss: 3006.4631 - val_mse: 3006.4631\n",
      "Epoch 371/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1167.8878 - mse: 1167.8878 - val_loss: 1281.5773 - val_mse: 1281.5773\n",
      "Epoch 372/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1219.2239 - mse: 1219.2239 - val_loss: 1839.1902 - val_mse: 1839.1902\n",
      "Epoch 373/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1081.5488 - mse: 1081.5488 - val_loss: 950.1478 - val_mse: 950.1478\n",
      "Epoch 374/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1112.5409 - mse: 1112.5409 - val_loss: 4342.6147 - val_mse: 4342.6147\n",
      "Epoch 375/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1600.0607 - mse: 1600.0607 - val_loss: 3833.9548 - val_mse: 3833.9548\n",
      "Epoch 376/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1239.6733 - mse: 1239.6733 - val_loss: 1877.0554 - val_mse: 1877.0554\n",
      "Epoch 377/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 761.1957 - mse: 761.1957 - val_loss: 1841.9059 - val_mse: 1841.9059\n",
      "Epoch 378/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1169.6647 - mse: 1169.6647 - val_loss: 1143.6746 - val_mse: 1143.6746\n",
      "Epoch 379/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 939.4022 - mse: 939.4021 - val_loss: 3370.6831 - val_mse: 3370.6831\n",
      "Epoch 380/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1516.6876 - mse: 1516.6876 - val_loss: 2229.9849 - val_mse: 2229.9849\n",
      "Epoch 381/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1310.3462 - mse: 1310.3462 - val_loss: 3231.8088 - val_mse: 3231.8088\n",
      "Epoch 382/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 933.5907 - mse: 933.5907 - val_loss: 2119.7810 - val_mse: 2119.7810\n",
      "Epoch 383/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1190.8429 - mse: 1190.8430 - val_loss: 1171.2228 - val_mse: 1171.2228\n",
      "Epoch 384/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1092.7026 - mse: 1092.7026 - val_loss: 2822.8047 - val_mse: 2822.8047\n",
      "Epoch 385/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 994.4812 - mse: 994.4812 - val_loss: 3564.8020 - val_mse: 3564.8020\n",
      "Epoch 386/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 553.8368 - mse: 553.8368 - val_loss: 2203.1672 - val_mse: 2203.1672\n",
      "Epoch 387/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1270.6798 - mse: 1270.6798 - val_loss: 958.5729 - val_mse: 958.5729\n",
      "Epoch 388/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 813.1918 - mse: 813.1918 - val_loss: 5081.7783 - val_mse: 5081.7783\n",
      "Epoch 389/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1685.4608 - mse: 1685.4608 - val_loss: 4019.0820 - val_mse: 4019.0820\n",
      "Epoch 390/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1156.9878 - mse: 1156.9878 - val_loss: 1095.4462 - val_mse: 1095.4462\n",
      "Epoch 391/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1171.9547 - mse: 1171.9547 - val_loss: 3580.6340 - val_mse: 3580.6340\n",
      "Epoch 392/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1238.7111 - mse: 1238.7111 - val_loss: 1744.9768 - val_mse: 1744.9768\n",
      "Epoch 393/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 827.6600 - mse: 827.6599 - val_loss: 862.9425 - val_mse: 862.9425\n",
      "Epoch 394/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 931.1221 - mse: 931.1221 - val_loss: 675.3927 - val_mse: 675.3927\n",
      "Epoch 395/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1170.2626 - mse: 1170.2628 - val_loss: 679.3481 - val_mse: 679.3481\n",
      "Epoch 396/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 975.7747 - mse: 975.7747 - val_loss: 2241.2576 - val_mse: 2241.2576\n",
      "Epoch 397/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1426.9650 - mse: 1426.9648 - val_loss: 7722.1489 - val_mse: 7722.1489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 936.6605 - mse: 936.6605 - val_loss: 6512.7720 - val_mse: 6512.7720\n",
      "Epoch 399/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1618.0660 - mse: 1618.0660 - val_loss: 1794.1395 - val_mse: 1794.1395\n",
      "Epoch 400/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1112.0815 - mse: 1112.0815 - val_loss: 1470.4929 - val_mse: 1470.4929\n",
      "Epoch 401/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1516.3083 - mse: 1516.3083 - val_loss: 2031.8346 - val_mse: 2031.8346\n",
      "Epoch 402/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 916.9742 - mse: 916.9742 - val_loss: 1575.3561 - val_mse: 1575.3561\n",
      "Epoch 403/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1392.3726 - mse: 1392.3726 - val_loss: 1630.9021 - val_mse: 1630.9021\n",
      "Epoch 404/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 794.6867 - mse: 794.6867 - val_loss: 1184.3430 - val_mse: 1184.3430\n",
      "Epoch 405/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1307.4308 - mse: 1307.4308 - val_loss: 3874.6899 - val_mse: 3874.6902\n",
      "Epoch 406/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1056.2482 - mse: 1056.2482 - val_loss: 2766.1255 - val_mse: 2766.1255\n",
      "Epoch 407/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 961.0880 - mse: 961.0880 - val_loss: 1980.4965 - val_mse: 1980.4965\n",
      "Epoch 408/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1030.3214 - mse: 1030.3214 - val_loss: 2751.5295 - val_mse: 2751.5295\n",
      "Epoch 409/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1602.3180 - mse: 1602.3180 - val_loss: 2431.4028 - val_mse: 2431.4028\n",
      "Epoch 410/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 807.0121 - mse: 807.0122 - val_loss: 2149.1799 - val_mse: 2149.1799\n",
      "Epoch 411/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1061.5311 - mse: 1061.5311 - val_loss: 2066.6243 - val_mse: 2066.6243\n",
      "Epoch 412/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 770.8262 - mse: 770.8262 - val_loss: 1243.4240 - val_mse: 1243.4240\n",
      "Epoch 413/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 989.9528 - mse: 989.9528 - val_loss: 3392.7168 - val_mse: 3392.7168\n",
      "Epoch 414/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1504.5305 - mse: 1504.5305 - val_loss: 3349.8391 - val_mse: 3349.8391\n",
      "Epoch 415/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 894.6184 - mse: 894.6184 - val_loss: 2235.7571 - val_mse: 2235.7571\n",
      "Epoch 416/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1304.3862 - mse: 1304.3862 - val_loss: 3508.8860 - val_mse: 3508.8860\n",
      "Epoch 417/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1263.3046 - mse: 1263.3044 - val_loss: 5364.5610 - val_mse: 5364.5610\n",
      "Epoch 418/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1443.3523 - mse: 1443.3523 - val_loss: 1579.8136 - val_mse: 1579.8136\n",
      "Epoch 419/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1234.1093 - mse: 1234.1093 - val_loss: 1340.4982 - val_mse: 1340.4982\n",
      "Epoch 420/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1172.3716 - mse: 1172.3716 - val_loss: 1893.8536 - val_mse: 1893.8536\n",
      "Epoch 421/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1094.8590 - mse: 1094.8590 - val_loss: 5339.6299 - val_mse: 5339.6299\n",
      "Epoch 422/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1350.5587 - mse: 1350.5587 - val_loss: 2529.6003 - val_mse: 2529.6003\n",
      "Epoch 423/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1110.6821 - mse: 1110.6821 - val_loss: 2537.3225 - val_mse: 2537.3225\n",
      "Epoch 424/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1006.5352 - mse: 1006.5352 - val_loss: 6295.3696 - val_mse: 6295.3696\n",
      "Epoch 425/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1788.9487 - mse: 1788.9487 - val_loss: 3972.0000 - val_mse: 3972.0000\n",
      "Epoch 426/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1455.5134 - mse: 1455.5134 - val_loss: 1986.3090 - val_mse: 1986.3090\n",
      "Epoch 427/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1188.6840 - mse: 1188.6840 - val_loss: 3070.7930 - val_mse: 3070.7930\n",
      "Epoch 428/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1085.3016 - mse: 1085.3016 - val_loss: 3817.2595 - val_mse: 3817.2595\n",
      "Epoch 429/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 990.5097 - mse: 990.5097 - val_loss: 3561.3098 - val_mse: 3561.3098\n",
      "Epoch 430/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 922.8945 - mse: 922.8945 - val_loss: 2366.9197 - val_mse: 2366.9197\n",
      "Epoch 431/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 891.8648 - mse: 891.8648 - val_loss: 3426.2964 - val_mse: 3426.2964\n",
      "Epoch 432/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1035.2362 - mse: 1035.2362 - val_loss: 1538.2166 - val_mse: 1538.2166\n",
      "Epoch 433/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1085.6921 - mse: 1085.6921 - val_loss: 2281.2332 - val_mse: 2281.2332\n",
      "Epoch 434/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 981.5762 - mse: 981.5762 - val_loss: 3405.7754 - val_mse: 3405.7754\n",
      "Epoch 435/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1234.5260 - mse: 1234.5260 - val_loss: 4390.9331 - val_mse: 4390.9331\n",
      "Epoch 436/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1323.8806 - mse: 1323.8806 - val_loss: 1666.1725 - val_mse: 1666.1725\n",
      "Epoch 437/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1054.0989 - mse: 1054.0989 - val_loss: 2462.0562 - val_mse: 2462.0562\n",
      "Epoch 438/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 966.3182 - mse: 966.3182 - val_loss: 3878.7605 - val_mse: 3878.7605\n",
      "Epoch 439/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 954.0834 - mse: 954.0834 - val_loss: 4897.7661 - val_mse: 4897.7661\n",
      "Epoch 440/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 806.6073 - mse: 806.6073 - val_loss: 2518.0747 - val_mse: 2518.0747\n",
      "Epoch 441/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1069.1854 - mse: 1069.1854 - val_loss: 1104.2053 - val_mse: 1104.2053\n",
      "Epoch 442/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 954.8728 - mse: 954.8728 - val_loss: 1720.4296 - val_mse: 1720.4296\n",
      "Epoch 443/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 826.0690 - mse: 826.0690 - val_loss: 1292.4941 - val_mse: 1292.4941\n",
      "Epoch 444/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 883.3310 - mse: 883.3310 - val_loss: 2693.4966 - val_mse: 2693.4963\n",
      "Epoch 445/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 808.5067 - mse: 808.5067 - val_loss: 4331.1797 - val_mse: 4331.1797\n",
      "Epoch 446/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1341.3051 - mse: 1341.3051 - val_loss: 3908.6111 - val_mse: 3908.6111\n",
      "Epoch 447/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1108.6027 - mse: 1108.6027 - val_loss: 1450.0764 - val_mse: 1450.0764\n",
      "Epoch 448/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1386.2119 - mse: 1386.2119 - val_loss: 1122.2059 - val_mse: 1122.2059\n",
      "Epoch 449/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1052.7144 - mse: 1052.7144 - val_loss: 2742.7651 - val_mse: 2742.7651\n",
      "Epoch 450/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 864.9745 - mse: 864.9745 - val_loss: 1922.7782 - val_mse: 1922.7782\n",
      "Epoch 451/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1123.4613 - mse: 1123.4613 - val_loss: 1499.4453 - val_mse: 1499.4453\n",
      "Epoch 452/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1304.8337 - mse: 1304.8337 - val_loss: 6787.5259 - val_mse: 6787.5259\n",
      "Epoch 453/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1089.1511 - mse: 1089.1511 - val_loss: 1004.2805 - val_mse: 1004.2805\n",
      "Epoch 454/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 895.6281 - mse: 895.6281 - val_loss: 2589.6890 - val_mse: 2589.6890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1136.3901 - mse: 1136.3901 - val_loss: 1859.5319 - val_mse: 1859.5319\n",
      "Epoch 456/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 904.5566 - mse: 904.5566 - val_loss: 4031.1616 - val_mse: 4031.1616\n",
      "Epoch 457/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 950.6544 - mse: 950.6544 - val_loss: 1217.4006 - val_mse: 1217.4006\n",
      "Epoch 458/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1052.1375 - mse: 1052.1376 - val_loss: 1898.7318 - val_mse: 1898.7318\n",
      "Epoch 459/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1257.6893 - mse: 1257.6893 - val_loss: 4422.8252 - val_mse: 4422.8252\n",
      "Epoch 460/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 823.8280 - mse: 823.8280 - val_loss: 1231.0988 - val_mse: 1231.0988\n",
      "Epoch 461/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1388.4418 - mse: 1388.4418 - val_loss: 9017.0225 - val_mse: 9017.0225\n",
      "Epoch 462/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1508.8978 - mse: 1508.8978 - val_loss: 4139.7827 - val_mse: 4139.7827\n",
      "Epoch 463/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 710.2519 - mse: 710.2519 - val_loss: 906.6078 - val_mse: 906.6078\n",
      "Epoch 464/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1034.2745 - mse: 1034.2745 - val_loss: 2292.5591 - val_mse: 2292.5591\n",
      "Epoch 465/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1152.4084 - mse: 1152.4084 - val_loss: 2434.1860 - val_mse: 2434.1863\n",
      "Epoch 466/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 974.1558 - mse: 974.1558 - val_loss: 789.5424 - val_mse: 789.5424\n",
      "Epoch 467/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1074.1987 - mse: 1074.1987 - val_loss: 2314.7937 - val_mse: 2314.7937\n",
      "Epoch 468/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1130.4969 - mse: 1130.4969 - val_loss: 817.8403 - val_mse: 817.8403\n",
      "Epoch 469/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1146.1185 - mse: 1146.1185 - val_loss: 4141.1787 - val_mse: 4141.1787\n",
      "Epoch 470/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1413.0944 - mse: 1413.0944 - val_loss: 6836.6982 - val_mse: 6836.6987\n",
      "Epoch 471/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1633.9855 - mse: 1633.9855 - val_loss: 3321.3733 - val_mse: 3321.3733\n",
      "Epoch 472/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1259.7341 - mse: 1259.7341 - val_loss: 1170.5656 - val_mse: 1170.5656\n",
      "Epoch 473/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1524.7700 - mse: 1524.7700 - val_loss: 1349.1969 - val_mse: 1349.1969\n",
      "Epoch 474/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 822.7812 - mse: 822.7812 - val_loss: 3489.3923 - val_mse: 3489.3923\n",
      "Epoch 475/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1085.6252 - mse: 1085.6254 - val_loss: 1050.8580 - val_mse: 1050.8580\n",
      "Epoch 476/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1110.4666 - mse: 1110.4666 - val_loss: 5394.2100 - val_mse: 5394.2100\n",
      "Epoch 477/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1314.9138 - mse: 1314.9138 - val_loss: 3194.5950 - val_mse: 3194.5950\n",
      "Epoch 478/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1123.1202 - mse: 1123.1202 - val_loss: 2614.0144 - val_mse: 2614.0144\n",
      "Epoch 479/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1171.5171 - mse: 1171.5171 - val_loss: 982.1930 - val_mse: 982.1931\n",
      "Epoch 480/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 807.6900 - mse: 807.6900 - val_loss: 2267.9392 - val_mse: 2267.9392\n",
      "Epoch 481/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 988.9180 - mse: 988.9180 - val_loss: 1843.6833 - val_mse: 1843.6832\n",
      "Epoch 482/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1110.5164 - mse: 1110.5164 - val_loss: 1865.1638 - val_mse: 1865.1638\n",
      "Epoch 483/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1099.2025 - mse: 1099.2025 - val_loss: 1351.3990 - val_mse: 1351.3990\n",
      "Epoch 484/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1375.4557 - mse: 1375.4557 - val_loss: 2017.2744 - val_mse: 2017.2744\n",
      "Epoch 485/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1507.6179 - mse: 1507.6179 - val_loss: 1845.3326 - val_mse: 1845.3326\n",
      "Epoch 486/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1108.5704 - mse: 1108.5704 - val_loss: 5519.2573 - val_mse: 5519.2578\n",
      "Epoch 487/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1226.8136 - mse: 1226.8136 - val_loss: 1799.7041 - val_mse: 1799.7041\n",
      "Epoch 488/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 746.1093 - mse: 746.1093 - val_loss: 2447.1780 - val_mse: 2447.1780\n",
      "Epoch 489/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1163.8010 - mse: 1163.8010 - val_loss: 4787.4624 - val_mse: 4787.4624\n",
      "Epoch 490/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1534.6102 - mse: 1534.6102 - val_loss: 1785.9550 - val_mse: 1785.9550\n",
      "Epoch 491/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1670.9573 - mse: 1670.9573 - val_loss: 5805.8823 - val_mse: 5805.8823\n",
      "Epoch 492/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1511.0128 - mse: 1511.0128 - val_loss: 5020.8159 - val_mse: 5020.8159\n",
      "Epoch 493/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1665.4943 - mse: 1665.4943 - val_loss: 2115.6719 - val_mse: 2115.6719\n",
      "Epoch 494/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1428.0685 - mse: 1428.0685 - val_loss: 4146.9360 - val_mse: 4146.9360\n",
      "Epoch 495/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1317.3735 - mse: 1317.3735 - val_loss: 6422.0010 - val_mse: 6422.0010\n",
      "Epoch 496/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1179.0468 - mse: 1179.0468 - val_loss: 2926.8796 - val_mse: 2926.8796\n",
      "Epoch 497/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1015.2787 - mse: 1015.2787 - val_loss: 1931.8835 - val_mse: 1931.8834\n",
      "Epoch 498/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1463.3583 - mse: 1463.3583 - val_loss: 3604.5269 - val_mse: 3604.5269\n",
      "Epoch 499/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1055.5610 - mse: 1055.5610 - val_loss: 2772.7397 - val_mse: 2772.7397\n",
      "Epoch 500/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1104.5343 - mse: 1104.5343 - val_loss: 2340.3940 - val_mse: 2340.3940\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, Y, epochs=500, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae984d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc17a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_train[-5:].values.reshape(1, 5, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b14c2cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[400.89575]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e7250a3b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[154.12567],\n",
       "       [157.45114],\n",
       "       [144.86499],\n",
       "       [131.59738],\n",
       "       [117.46091],\n",
       "       [128.71347],\n",
       "       [129.04085],\n",
       "       [135.738  ],\n",
       "       [149.13551],\n",
       "       [147.56976],\n",
       "       [142.54855],\n",
       "       [153.9989 ],\n",
       "       [160.41995],\n",
       "       [165.81235],\n",
       "       [154.12567],\n",
       "       [140.7785 ],\n",
       "       [126.78404],\n",
       "       [140.85423],\n",
       "       [141.52295],\n",
       "       [149.59787],\n",
       "       [169.8825 ],\n",
       "       [167.05136],\n",
       "       [168.09921],\n",
       "       [188.60266],\n",
       "       [209.20657],\n",
       "       [205.55106],\n",
       "       [181.53084],\n",
       "       [161.8913 ],\n",
       "       [144.23044],\n",
       "       [164.35356],\n",
       "       [169.37567],\n",
       "       [174.8605 ],\n",
       "       [201.18459],\n",
       "       [197.54552],\n",
       "       [195.03134],\n",
       "       [220.78798],\n",
       "       [239.42027],\n",
       "       [238.5318 ],\n",
       "       [208.50508],\n",
       "       [188.1831 ],\n",
       "       [168.74269],\n",
       "       [194.72589],\n",
       "       [201.35724],\n",
       "       [202.01208],\n",
       "       [233.74803],\n",
       "       [224.46342],\n",
       "       [232.71219],\n",
       "       [278.77292],\n",
       "       [309.50082],\n",
       "       [291.83426],\n",
       "       [246.0827 ],\n",
       "       [216.48178],\n",
       "       [192.94138],\n",
       "       [220.19507],\n",
       "       [220.42728],\n",
       "       [214.11813],\n",
       "       [245.49152],\n",
       "       [226.41248],\n",
       "       [233.34305],\n",
       "       [274.29926],\n",
       "       [307.08746],\n",
       "       [303.7822 ],\n",
       "       [268.3663 ],\n",
       "       [235.22424],\n",
       "       [211.96654],\n",
       "       [240.90036],\n",
       "       [242.84476],\n",
       "       [236.61641],\n",
       "       [281.22513],\n",
       "       [269.54892],\n",
       "       [278.7214 ],\n",
       "       [331.6472 ],\n",
       "       [370.32883],\n",
       "       [359.6788 ],\n",
       "       [320.41623],\n",
       "       [277.28683],\n",
       "       [251.77185],\n",
       "       [282.00223],\n",
       "       [282.12866],\n",
       "       [274.97235],\n",
       "       [326.58133],\n",
       "       [317.0074 ],\n",
       "       [331.7252 ],\n",
       "       [384.1543 ],\n",
       "       [426.44305],\n",
       "       [413.56146],\n",
       "       [363.9706 ],\n",
       "       [314.7199 ],\n",
       "       [282.00137],\n",
       "       [309.6122 ],\n",
       "       [313.299  ],\n",
       "       [300.47165],\n",
       "       [354.58524],\n",
       "       [343.58286],\n",
       "       [361.11752],\n",
       "       [412.9648 ],\n",
       "       [455.3146 ],\n",
       "       [445.29938],\n",
       "       [397.2197 ],\n",
       "       [346.82336],\n",
       "       [309.57852],\n",
       "       [337.69073],\n",
       "       [342.34396],\n",
       "       [325.20303],\n",
       "       [377.09412],\n",
       "       [362.4128 ],\n",
       "       [372.56293],\n",
       "       [418.05002],\n",
       "       [460.5308 ],\n",
       "       [451.6555 ],\n",
       "       [409.54037],\n",
       "       [363.1185 ],\n",
       "       [314.26587],\n",
       "       [343.5225 ],\n",
       "       [346.34283],\n",
       "       [326.9424 ],\n",
       "       [385.07755],\n",
       "       [376.08542],\n",
       "       [394.3701 ],\n",
       "       [443.19974],\n",
       "       [486.39423],\n",
       "       [472.05875],\n",
       "       [434.1544 ],\n",
       "       [388.09006],\n",
       "       [342.28622],\n",
       "       [371.58487],\n",
       "       [381.12234],\n",
       "       [368.94937],\n",
       "       [422.36234],\n",
       "       [411.03256],\n",
       "       [412.86612],\n",
       "       [464.28482],\n",
       "       [503.49612],\n",
       "       [491.31326],\n",
       "       [458.33786],\n",
       "       [409.3798 ],\n",
       "       [363.76993]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae58472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
