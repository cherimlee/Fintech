{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91d195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7566a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76015</th>\n",
       "      <td>151829</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60926.490000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76016</th>\n",
       "      <td>151830</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118634.520000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76017</th>\n",
       "      <td>151835</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74028.150000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76018</th>\n",
       "      <td>151836</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84278.160000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76019</th>\n",
       "      <td>151838</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76020 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0           1     2     23                 0.0                      0.0   \n",
       "1           3     2     34                 0.0                      0.0   \n",
       "2           4     2     23                 0.0                      0.0   \n",
       "3           8     2     37                 0.0                    195.0   \n",
       "4          10     2     39                 0.0                      0.0   \n",
       "...       ...   ...    ...                 ...                      ...   \n",
       "76015  151829     2     48                 0.0                      0.0   \n",
       "76016  151830     2     39                 0.0                      0.0   \n",
       "76017  151835     2     23                 0.0                      0.0   \n",
       "76018  151836     2     25                 0.0                      0.0   \n",
       "76019  151838     2     46                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                        195.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "76015                      0.0                      0.0   \n",
       "76016                      0.0                      0.0   \n",
       "76017                      0.0                      0.0   \n",
       "76018                      0.0                      0.0   \n",
       "76019                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "76015                      0.0                      0.0   \n",
       "76016                      0.0                      0.0   \n",
       "76017                      0.0                      0.0   \n",
       "76018                      0.0                      0.0   \n",
       "76019                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  ...  saldo_medio_var33_hace2  \\\n",
       "0                          0.0  ...                      0.0   \n",
       "1                          0.0  ...                      0.0   \n",
       "2                          0.0  ...                      0.0   \n",
       "3                          0.0  ...                      0.0   \n",
       "4                          0.0  ...                      0.0   \n",
       "...                        ...  ...                      ...   \n",
       "76015                      0.0  ...                      0.0   \n",
       "76016                      0.0  ...                      0.0   \n",
       "76017                      0.0  ...                      0.0   \n",
       "76018                      0.0  ...                      0.0   \n",
       "76019                      0.0  ...                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "76015                      0.0                     0.0   \n",
       "76016                      0.0                     0.0   \n",
       "76017                      0.0                     0.0   \n",
       "76018                      0.0                     0.0   \n",
       "76019                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "76015                     0.0                      0.0   \n",
       "76016                     0.0                      0.0   \n",
       "76017                     0.0                      0.0   \n",
       "76018                     0.0                      0.0   \n",
       "76019                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "76015                      0.0                     0.0   \n",
       "76016                      0.0                     0.0   \n",
       "76017                      0.0                     0.0   \n",
       "76018                      0.0                     0.0   \n",
       "76019                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                         0.0   39205.170000       0  \n",
       "1                         0.0   49278.030000       0  \n",
       "2                         0.0   67333.770000       0  \n",
       "3                         0.0   64007.970000       0  \n",
       "4                         0.0  117310.979016       0  \n",
       "...                       ...            ...     ...  \n",
       "76015                     0.0   60926.490000       0  \n",
       "76016                     0.0  118634.520000       0  \n",
       "76017                     0.0   74028.150000       0  \n",
       "76018                     0.0   84278.160000       0  \n",
       "76019                     0.0  117310.979016       0  \n",
       "\n",
       "[76020 rows x 371 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ml_source_files/santander_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 불만족: 1, 만족: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11476e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73012\n",
       "1     3008\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c446a9a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9c7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치(outlier) 제거\n",
    "\n",
    "df.var3.value_counts().sort_index()\n",
    "df['var3'].replace(-999999, 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fdb1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y data divide\n",
    "y = df['TARGET']\n",
    "x = df.drop('TARGET', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2e31e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d83e896",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0     2     23                 0.0                      0.0   \n",
       "1     2     34                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "0                      0.0                      0.0                0.0  ...   \n",
       "1                      0.0                      0.0                0.0  ...   \n",
       "\n",
       "   saldo_medio_var29_ult3  saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var33_ult1  saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0                     0.0                     0.0                      0.0   \n",
       "1                     0.0                     0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_hace3  saldo_medio_var44_ult1  saldo_medio_var44_ult3  \\\n",
       "0                      0.0                     0.0                     0.0   \n",
       "1                      0.0                     0.0                     0.0   \n",
       "\n",
       "      var38  \n",
       "0  39205.17  \n",
       "1  49278.03  \n",
       "\n",
       "[2 rows x 369 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b28da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5164ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfff666c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.81932\tvalidation_1-auc:0.81599\n",
      "[1]\tvalidation_0-auc:0.83303\tvalidation_1-auc:0.82568\n",
      "[2]\tvalidation_0-auc:0.83646\tvalidation_1-auc:0.82604\n",
      "[3]\tvalidation_0-auc:0.84284\tvalidation_1-auc:0.83156\n",
      "[4]\tvalidation_0-auc:0.84524\tvalidation_1-auc:0.83115\n",
      "[5]\tvalidation_0-auc:0.85059\tvalidation_1-auc:0.83228\n",
      "[6]\tvalidation_0-auc:0.85535\tvalidation_1-auc:0.83479\n",
      "[7]\tvalidation_0-auc:0.85750\tvalidation_1-auc:0.83698\n",
      "[8]\tvalidation_0-auc:0.86231\tvalidation_1-auc:0.83794\n",
      "[9]\tvalidation_0-auc:0.86491\tvalidation_1-auc:0.83965\n",
      "[10]\tvalidation_0-auc:0.86928\tvalidation_1-auc:0.84051\n",
      "[11]\tvalidation_0-auc:0.87138\tvalidation_1-auc:0.84064\n",
      "[12]\tvalidation_0-auc:0.87529\tvalidation_1-auc:0.84199\n",
      "[13]\tvalidation_0-auc:0.87817\tvalidation_1-auc:0.84147\n",
      "[14]\tvalidation_0-auc:0.88015\tvalidation_1-auc:0.84172\n",
      "[15]\tvalidation_0-auc:0.88201\tvalidation_1-auc:0.84232\n",
      "[16]\tvalidation_0-auc:0.88378\tvalidation_1-auc:0.84255\n",
      "[17]\tvalidation_0-auc:0.88539\tvalidation_1-auc:0.84241\n",
      "[18]\tvalidation_0-auc:0.88611\tvalidation_1-auc:0.84205\n",
      "[19]\tvalidation_0-auc:0.88671\tvalidation_1-auc:0.84223\n",
      "[20]\tvalidation_0-auc:0.88816\tvalidation_1-auc:0.84238\n",
      "[21]\tvalidation_0-auc:0.89023\tvalidation_1-auc:0.84169\n",
      "[22]\tvalidation_0-auc:0.89084\tvalidation_1-auc:0.84226\n",
      "[23]\tvalidation_0-auc:0.89113\tvalidation_1-auc:0.84225\n",
      "[24]\tvalidation_0-auc:0.89328\tvalidation_1-auc:0.84246\n",
      "[25]\tvalidation_0-auc:0.89449\tvalidation_1-auc:0.84212\n",
      "[26]\tvalidation_0-auc:0.89486\tvalidation_1-auc:0.84184\n",
      "[27]\tvalidation_0-auc:0.89558\tvalidation_1-auc:0.84194\n",
      "[28]\tvalidation_0-auc:0.89707\tvalidation_1-auc:0.84181\n",
      "[29]\tvalidation_0-auc:0.89754\tvalidation_1-auc:0.84196\n",
      "[30]\tvalidation_0-auc:0.89807\tvalidation_1-auc:0.84228\n",
      "[31]\tvalidation_0-auc:0.89819\tvalidation_1-auc:0.84243\n",
      "[32]\tvalidation_0-auc:0.89871\tvalidation_1-auc:0.84235\n",
      "[33]\tvalidation_0-auc:0.89907\tvalidation_1-auc:0.84199\n",
      "[34]\tvalidation_0-auc:0.90011\tvalidation_1-auc:0.84154\n",
      "[35]\tvalidation_0-auc:0.90282\tvalidation_1-auc:0.84137\n",
      "[36]\tvalidation_0-auc:0.90508\tvalidation_1-auc:0.84033\n",
      "[37]\tvalidation_0-auc:0.90635\tvalidation_1-auc:0.84038\n",
      "[38]\tvalidation_0-auc:0.90722\tvalidation_1-auc:0.84016\n",
      "[39]\tvalidation_0-auc:0.90768\tvalidation_1-auc:0.83996\n",
      "[40]\tvalidation_0-auc:0.90778\tvalidation_1-auc:0.84003\n",
      "[41]\tvalidation_0-auc:0.90986\tvalidation_1-auc:0.84014\n",
      "[42]\tvalidation_0-auc:0.91028\tvalidation_1-auc:0.83965\n",
      "[43]\tvalidation_0-auc:0.91054\tvalidation_1-auc:0.83981\n",
      "[44]\tvalidation_0-auc:0.91075\tvalidation_1-auc:0.83977\n",
      "[45]\tvalidation_0-auc:0.91081\tvalidation_1-auc:0.83967\n",
      "[46]\tvalidation_0-auc:0.91132\tvalidation_1-auc:0.83967\n",
      "[47]\tvalidation_0-auc:0.91216\tvalidation_1-auc:0.83975\n",
      "[48]\tvalidation_0-auc:0.91347\tvalidation_1-auc:0.83966\n",
      "[49]\tvalidation_0-auc:0.91393\tvalidation_1-auc:0.83922\n",
      "[50]\tvalidation_0-auc:0.91533\tvalidation_1-auc:0.83797\n",
      "[51]\tvalidation_0-auc:0.91639\tvalidation_1-auc:0.83739\n",
      "[52]\tvalidation_0-auc:0.91753\tvalidation_1-auc:0.83644\n",
      "[53]\tvalidation_0-auc:0.91796\tvalidation_1-auc:0.83628\n",
      "[54]\tvalidation_0-auc:0.91819\tvalidation_1-auc:0.83643\n",
      "[55]\tvalidation_0-auc:0.91892\tvalidation_1-auc:0.83625\n",
      "[56]\tvalidation_0-auc:0.91925\tvalidation_1-auc:0.83629\n",
      "[57]\tvalidation_0-auc:0.91997\tvalidation_1-auc:0.83616\n",
      "[58]\tvalidation_0-auc:0.92005\tvalidation_1-auc:0.83629\n",
      "[59]\tvalidation_0-auc:0.92012\tvalidation_1-auc:0.83603\n",
      "[60]\tvalidation_0-auc:0.92025\tvalidation_1-auc:0.83614\n",
      "[61]\tvalidation_0-auc:0.92105\tvalidation_1-auc:0.83560\n",
      "[62]\tvalidation_0-auc:0.92181\tvalidation_1-auc:0.83539\n",
      "[63]\tvalidation_0-auc:0.92194\tvalidation_1-auc:0.83523\n",
      "[64]\tvalidation_0-auc:0.92234\tvalidation_1-auc:0.83525\n",
      "[65]\tvalidation_0-auc:0.92273\tvalidation_1-auc:0.83517\n",
      "[66]\tvalidation_0-auc:0.92285\tvalidation_1-auc:0.83523\n",
      "[67]\tvalidation_0-auc:0.92295\tvalidation_1-auc:0.83542\n",
      "[68]\tvalidation_0-auc:0.92368\tvalidation_1-auc:0.83509\n",
      "[69]\tvalidation_0-auc:0.92473\tvalidation_1-auc:0.83448\n",
      "[70]\tvalidation_0-auc:0.92505\tvalidation_1-auc:0.83413\n",
      "[71]\tvalidation_0-auc:0.92627\tvalidation_1-auc:0.83379\n",
      "[72]\tvalidation_0-auc:0.92672\tvalidation_1-auc:0.83351\n",
      "[73]\tvalidation_0-auc:0.92778\tvalidation_1-auc:0.83328\n",
      "[74]\tvalidation_0-auc:0.92840\tvalidation_1-auc:0.83300\n",
      "[75]\tvalidation_0-auc:0.92897\tvalidation_1-auc:0.83320\n",
      "[76]\tvalidation_0-auc:0.92994\tvalidation_1-auc:0.83294\n",
      "[77]\tvalidation_0-auc:0.93030\tvalidation_1-auc:0.83250\n",
      "[78]\tvalidation_0-auc:0.93065\tvalidation_1-auc:0.83212\n",
      "[79]\tvalidation_0-auc:0.93094\tvalidation_1-auc:0.83209\n",
      "[80]\tvalidation_0-auc:0.93174\tvalidation_1-auc:0.83219\n",
      "[81]\tvalidation_0-auc:0.93247\tvalidation_1-auc:0.83194\n",
      "[82]\tvalidation_0-auc:0.93316\tvalidation_1-auc:0.83147\n",
      "[83]\tvalidation_0-auc:0.93325\tvalidation_1-auc:0.83151\n",
      "[84]\tvalidation_0-auc:0.93332\tvalidation_1-auc:0.83154\n",
      "[85]\tvalidation_0-auc:0.93341\tvalidation_1-auc:0.83131\n",
      "[86]\tvalidation_0-auc:0.93353\tvalidation_1-auc:0.83125\n",
      "[87]\tvalidation_0-auc:0.93364\tvalidation_1-auc:0.83127\n",
      "[88]\tvalidation_0-auc:0.93369\tvalidation_1-auc:0.83112\n",
      "[89]\tvalidation_0-auc:0.93375\tvalidation_1-auc:0.83094\n",
      "[90]\tvalidation_0-auc:0.93444\tvalidation_1-auc:0.83087\n",
      "[91]\tvalidation_0-auc:0.93463\tvalidation_1-auc:0.83069\n",
      "[92]\tvalidation_0-auc:0.93477\tvalidation_1-auc:0.83061\n",
      "[93]\tvalidation_0-auc:0.93588\tvalidation_1-auc:0.83057\n",
      "[94]\tvalidation_0-auc:0.93607\tvalidation_1-auc:0.83042\n",
      "[95]\tvalidation_0-auc:0.93638\tvalidation_1-auc:0.82994\n",
      "[96]\tvalidation_0-auc:0.93671\tvalidation_1-auc:0.82919\n",
      "[97]\tvalidation_0-auc:0.93700\tvalidation_1-auc:0.82878\n",
      "[98]\tvalidation_0-auc:0.93763\tvalidation_1-auc:0.82800\n",
      "[99]\tvalidation_0-auc:0.93811\tvalidation_1-auc:0.82786\n",
      "[100]\tvalidation_0-auc:0.93840\tvalidation_1-auc:0.82769\n",
      "[101]\tvalidation_0-auc:0.93877\tvalidation_1-auc:0.82791\n",
      "[102]\tvalidation_0-auc:0.93887\tvalidation_1-auc:0.82792\n",
      "[103]\tvalidation_0-auc:0.93923\tvalidation_1-auc:0.82752\n",
      "[104]\tvalidation_0-auc:0.93958\tvalidation_1-auc:0.82689\n",
      "[105]\tvalidation_0-auc:0.93971\tvalidation_1-auc:0.82659\n",
      "[106]\tvalidation_0-auc:0.94029\tvalidation_1-auc:0.82636\n",
      "[107]\tvalidation_0-auc:0.94093\tvalidation_1-auc:0.82626\n",
      "[108]\tvalidation_0-auc:0.94203\tvalidation_1-auc:0.82550\n",
      "[109]\tvalidation_0-auc:0.94225\tvalidation_1-auc:0.82542\n",
      "[110]\tvalidation_0-auc:0.94257\tvalidation_1-auc:0.82495\n",
      "[111]\tvalidation_0-auc:0.94350\tvalidation_1-auc:0.82475\n",
      "[112]\tvalidation_0-auc:0.94382\tvalidation_1-auc:0.82484\n",
      "[113]\tvalidation_0-auc:0.94417\tvalidation_1-auc:0.82464\n",
      "[114]\tvalidation_0-auc:0.94424\tvalidation_1-auc:0.82437\n",
      "[115]\tvalidation_0-auc:0.94490\tvalidation_1-auc:0.82396\n",
      "[116]\tvalidation_0-auc:0.94541\tvalidation_1-auc:0.82365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=500, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=111,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=500, random_state=111)\n",
    "xgb_clf.fit(x_train, y_train, early_stopping_rounds=100, eval_metric='auc',\\\n",
    "           eval_set = [(x_train, y_train), (x_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bbcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cec515e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d9594fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55d87a31",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     21866\n",
      "           1       0.62      0.01      0.01       940\n",
      "\n",
      "    accuracy                           0.96     22806\n",
      "   macro avg       0.79      0.50      0.49     22806\n",
      "weighted avg       0.95      0.96      0.94     22806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eccf442f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 76, in _train_internal\n",
      "    bst = callbacks.before_training(bst)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 378, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\", line 538, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2194, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: Some trailing characters could not be parsed: ',0.7'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "Some trailing characters could not be parsed: ',0.7'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14084/3878081841.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m grid.fit(x_train, y_train, early_stopping_rounds=30, eval_metric='auc',\\\n\u001b[0m\u001b[0;32m     10\u001b[0m         eval_set=[(x_train, y_train),(x_test, y_test)])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         )\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1251\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     74\u001b[0m             show_stdv=False, cvfolds=None)\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mbefore_training\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;34m'''Function called before training.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'before_training should return the model'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mbefore_training\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbefore_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstarting_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_boosted_rounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mnum_boosted_rounds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2192\u001b[0m         \u001b[0mrounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2193\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2194\u001b[1;33m         \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterBoostedRounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2195\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrounds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \"\"\"\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: Some trailing characters could not be parsed: ',0.7'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_cls = XGBClassifier(n_estimators=100)\n",
    "\n",
    "params = {'max_depth':[5,7],'min_child_weight':[1,3], \\\n",
    "         'colsample_bytree':[\"0.5,0.7\"]}\n",
    "\n",
    "grid = GridSearchCV(xgb_cls, param_grid = params)\n",
    "grid.fit(x_train, y_train, early_stopping_rounds=30, eval_metric='auc',\\\n",
    "        eval_set=[(x_train, y_train),(x_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1cc5582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': '0.5,0.7', 'max_depth': 5, 'min_child_weight': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69ef23ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e4fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8154c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36cf55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c38b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f63de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734be22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d807a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38423a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae0b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c6036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1975b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51d12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
